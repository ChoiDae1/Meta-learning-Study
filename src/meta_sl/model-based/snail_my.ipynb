{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmeta.datasets.helpers import omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(32, 2, 30)\n",
    "conv1d = torch.nn.Conv1d(in_channels = 2, out_channels = 4, kernel_size=3, groups=2)\n",
    "output = conv1d(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNAIL 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casual convolution block\n",
    "class CasualConv1d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "        groups: int = 1,\n",
    "        bias: int = True,\n",
    "    ) -> None:\n",
    "       super(CasualConv1d, self).__init__()\n",
    "       self.dilation = dilation\n",
    "       padding = dilation * (kernel_size - 1) # kenel_size = 2로 하고 -self.dilation 만큼 자르면, input_size와 같음\n",
    "       self.conv1d = nn.Conv1d(\n",
    "           in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias\n",
    "       )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.conv1d(x)\n",
    "        return out[:, :, : -self.dilation] # [batch_size, out_channels, input_size], padding을 양쪽에 붙였기에, 오른쪽 제거 -> casual convolution \n",
    "\n",
    "# DenseBlock\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, dilation: int, filters: int, kernel_size: int = 2) -> None:\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.casual_conv1 = CasualConv1d(in_channels, filters, kernel_size, dilation=dilation)\n",
    "        self.casual_conv2 = CasualConv1d(in_channels, filters, kernel_size, dilation=dilation)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        xf = self.casual_conv1(x)\n",
    "        xg = self.casual_conv2(x)\n",
    "        activation  = torch.tanh(xf) * torch.sigmoid(xg)\n",
    "        return torch.cat((x, activation), dim=1) # [batch_size, in_channels + filters, input_size]\n",
    "\n",
    "# Temporal convolution block (TCBlock)\n",
    "class TCBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, seq_length: int, filters: int) -> None:\n",
    "        super(TCBlock, self).__init__()\n",
    "        self.dense_blocks = nn.ModuleList(\n",
    "            [\n",
    "                DenseBlock(in_channels + i * filters, 2 ** (i + 1), filters)\n",
    "                for i in range(int(math.ceil(math.log(seq_length, 2))))\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.transpose(x, 1, 2) # [batch_size, in_channels, input_size] = [batch_size, in_channels, num_ways*shots + 1] = [batch_size, in_channels, seq_len]\n",
    "        for block in self.dense_blocks:\n",
    "            x = block(x)\n",
    "        return torch.transpose(x, 1, 2) # [batch_size, input_size, in_channels + int(math.ceil(math.log(seq_length, 2)) * filters ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttentionBlock\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, key_size: int, value_size: int) -> None:\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.query_layer = nn.Linear(in_channels, key_size)\n",
    "        self.keys_layer = nn.Linear(in_channels, key_size)\n",
    "        self.values_layer = nn.Linear(in_channels, value_size)\n",
    "        #self.sqrt_key_size = math.sqrt(key_size)\n",
    "        self.key_size = key_size\n",
    "    \n",
    "    @classmethod\n",
    "    def causally_masked_softmax(cls, logits: torch.Tensor, key_size: int) -> torch.Tensor:\n",
    "        seq_len = logits.shape[1]\n",
    "        mask = np.array([[i > j for i in range(seq_len)] for j in range(seq_len)])\n",
    "        mask = torch.BoolTensor(mask).to(logits.get_device())\n",
    "\n",
    "        logits = logits.data.masked_fill(mask, -float(\"inf\"))\n",
    "        return F.softmax(logits / math.sqrt(key_size), dim=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        keys = self.keys_layer(x) # [batch_size, seq_len, key_size], C = num_ways * num_shots + 1\n",
    "        query = self.query_layer(x) # [batch_size, seq_len, key_size]\n",
    "        logits = torch.bmm(query, torch.transpose(keys, 1, 2)) # [batch_size, seq_len, seq_len]\n",
    "\n",
    "        probs = self.causally_masked_softmax(logits, self.key_size) # [batch_size, seq_len, seq_len]\n",
    "        values = self.values_layer(x) # [batch_size, seq_len, value_size]\n",
    "\n",
    "        read = torch.bmm(probs, values) # [batch_size, seq_len, value_size]\n",
    "        return torch.cat((x, read), dim=2) # [batch_size, seq_len, in_channels + value_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([352, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(32, 11, 1, 28, 28)\n",
    "input_ = input.reshape((-1, *input.shape[2:]))\n",
    "print(input_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Network\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, x_dim: int=1, hid_dim: int = 64, z_dim: int = 64) -> None:\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.conv_block(in_channels = x_dim, out_channels=hid_dim),\n",
    "            self.conv_block(in_channels = hid_dim, out_channels=hid_dim),\n",
    "            self.conv_block(in_channels = hid_dim, out_channels=hid_dim),\n",
    "            self.conv_block(in_channels = hid_dim, out_channels=z_dim),\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def conv_block(cls, in_channels: int, out_channels: int) -> nn.Sequential:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels, momentum=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoder(x)\n",
    "        out = x.view(x.size(0), -1)\n",
    "        return out\n",
    "    \n",
    "\n",
    "# SNAIL\n",
    "class SNAIL(nn.Module):\n",
    "    def __init__(self, num_ways: int, num_shots: int) -> None:\n",
    "        super(SNAIL, self).__init__()\n",
    "        self.num_ways, self.num_shots = num_ways, num_shots\n",
    "        self.seq_len = self.num_ways * self.num_shots + 1\n",
    "\n",
    "        self.encoder = EmbeddingNet()\n",
    "        num_channels = 64 + num_ways # foward 연산시 embedding한 뒤에 y_label과 concat함\n",
    "        num_filters = int(math.ceil(math.log(self.seq_len, 2))) # TCBlock 통과시 Dense 연산 횟수임.\n",
    "\n",
    "        self.attention1 = AttentionBlock(num_channels, 64, 32)\n",
    "        num_channels += 32\n",
    "        self.tc1 = TCBlock(num_channels, self.seq_len, 128)\n",
    "        num_channels += num_filters * 128 \n",
    "\n",
    "        self.attention2 = AttentionBlock(num_channels, 256, 128)\n",
    "        num_channels += 128\n",
    "        self.tc2 = TCBlock(num_channels, self.seq_len, 128)\n",
    "        num_channels += num_filters * 128\n",
    "       \n",
    "        self.attention3 = AttentionBlock(num_channels, 512, 256)\n",
    "        num_channels += 256\n",
    "        self.fc = nn.Linear(num_channels, num_ways)\n",
    "\n",
    "\n",
    "    def forward(self, x_seq: torch.Tensor, y_seq: torch.Tensor) -> torch.Tensor: # x_seq: [batch_size*seq_len, 1, 28, 28], y_seq: [batch_size*seq_len, ways]\n",
    "        x_emb = self.encoder(x_seq) # [batch_size * seq_len, 64]\n",
    "        batch_size = int(y_seq.size()[0] / self.seq_len)\n",
    "\n",
    "        # query_y는 예측을 위해 label을 0으로 만들어줌.\n",
    "        last_idxs = [(i + 1) * (self.seq_len) -1 for i in range(batch_size)]\n",
    "        y_seq[last_idxs] = torch.Tensor(np.zeros((batch_size, y_seq.size()[1]))).to(y_seq.get_device())\n",
    "\n",
    "        x_cat = torch.cat((x_emb, y_seq), dim=1) \n",
    "        x_view = x_cat.view((batch_size, self.seq_len, -1)) # [batch_size, seq_len, 64+ways]\n",
    "\n",
    "        x_att1 = self.attention1(x_view)\n",
    "        x_tc1 = self.tc1(x_att1)\n",
    "\n",
    "        x_att2 = self.attention2(x_tc1)\n",
    "        x_tc2 = self.tc2(x_att2)\n",
    "\n",
    "        x_att3 = self.attention3(x_tc2)\n",
    "        x_out = self.fc(x_att3) \n",
    "        return x_out # [batch_size, seq_len, num_ways]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = SNAIL(num_ways=config[\"num_ways\"], num_shots=config[\"num_shots\"]).to(\\n    device=config[\"device\"]\\n)\\n\\nx_seq = torch.randn(192, 1, 28, 28).to(\"cuda\")\\ny_seq = torch.randn(192, 5).to(\"cuda\")\\noutput = model(x_seq, y_seq)\\noutput.shape'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = SNAIL(num_ways=config[\"num_ways\"], num_shots=config[\"num_shots\"]).to(\n",
    "    device=config[\"device\"]\n",
    ")\n",
    "\n",
    "x_seq = torch.randn(192, 1, 28, 28).to(\"cuda\")\n",
    "y_seq = torch.randn(192, 5).to(\"cuda\")\n",
    "output = model(x_seq, y_seq)\n",
    "output.shape'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(\n",
    "    task_batch: Dict[str, List[torch.Tensor]], device: str, num_ways: int, num_shots: int\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "   support_xs = task_batch[\"train\"][0].to(device=device) # [batch_size, 5, 1, 28, 28]\n",
    "   support_ys = task_batch[\"train\"][1].to(device=device)\n",
    "   query_xs = task_batch[\"test\"][0].to(device=device)\n",
    "   query_ys = task_batch[\"test\"][1].to(device=device)\n",
    "\n",
    "   chosen_indices = torch.randint(query_xs.shape[1], size=(query_xs.shape[0],))\n",
    "   chosen_query_xs = query_xs[torch.arange(query_xs.shape[0]), chosen_indices, :, :, :].unsqueeze(1) # [batch_size, 1, 1, 28, 28]\n",
    "   chosen_query_ys = query_ys[torch.arange(query_ys.shape[0]), chosen_indices].unsqueeze(1) # [batch_size, 1]\n",
    "   #print(chosen_query_xs.shape)\n",
    "   #print(chosen_query_ys.shape)\n",
    "   x_seq = torch.cat((support_xs, chosen_query_xs), dim=1).reshape((-1, *support_xs.shape[2:])) # [batch_size * (5 + 1), 1, 28, 28] = [192, 1, 28, 28]\n",
    "   y_seq = torch.cat((support_ys, chosen_query_ys), dim=1).reshape((-1, *support_ys.shape[2:])) # [batch_size * (5 + 1)] = [192]\n",
    "   #print(x_seq.shape)\n",
    "   #print(y_seq.shape)\n",
    "\n",
    "   y_seq_onehot = F.one_hot(y_seq).float() # [192, 5]\n",
    "\n",
    "   query_y = y_seq[:: (num_ways * num_shots + 1)].long() # [32] -> 타깃이 되는 맨 마지막 이미지의 정답 레이블임.\n",
    "   #print(y_seq_onehot.shape)\n",
    "   #print(query_y.shape)\n",
    "   return x_seq, y_seq_onehot, query_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, train_batch in enumerate(train_dataloader):\\n    x_seq, y_seq_onehot, query_y = generate_sequence(train_batch, config[\"device\"], config[\"num_ways\"], config[\"num_shots\"])\\n    break'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i, train_batch in enumerate(train_dataloader):\n",
    "    x_seq, y_seq_onehot, query_y = generate_sequence(train_batch, config[\"device\"], config[\"num_ways\"], config[\"num_shots\"])\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습함수 정의\n",
    "def train_snail(\n",
    "    num_ways: int,\n",
    "    num_shots: int,\n",
    "    device: str,\n",
    "    task_batch: Dict[str, List[torch.Tensor]],\n",
    "    model: SNAIL,\n",
    "    criterion: nn.CrossEntropyLoss,\n",
    "    optimizer: torch.optim.Adam,\n",
    ") -> Tuple[float, float]:\n",
    "   model.train()\n",
    "   optimizer.zero_grad()\n",
    "\n",
    "   x_seq, y_seq, query_y = generate_sequence(\n",
    "       task_batch=task_batch, device=device, num_ways=num_ways, num_shots=num_shots\n",
    "   )\n",
    "   x_seq = x_seq.to(device=device)\n",
    "   y_seq = y_seq.to(device=device)\n",
    "   query_y = query_y.to(device=device)\n",
    "\n",
    "   query_prob = model(x_seq, y_seq)[:, -1, :] # [batch_size, num_ways]\n",
    "   loss = criterion(query_prob, query_y)\n",
    "\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "   with torch.no_grad():\n",
    "      _, query_preds = query_prob.max(dim=1)\n",
    "      accuracy = torch.eq(query_preds, query_y).float().mean()\n",
    "\n",
    "   return accuracy.item(), loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트함수 정의\n",
    "def test_snail(\n",
    "    num_ways: int,\n",
    "    num_shots: int,\n",
    "    device: str,\n",
    "    task_batch: Dict[str, List[torch.Tensor]],\n",
    "    model: SNAIL,\n",
    "    criterion: nn.CrossEntropyLoss,\n",
    ") -> Tuple[float, float]:\n",
    "   model.eval()\n",
    "\n",
    "   x_seq, y_seq, query_y = generate_sequence(\n",
    "       task_batch=task_batch, device=device, num_ways=num_ways, num_shots=num_shots\n",
    "   )\n",
    "   x_seq = x_seq.to(device=device)\n",
    "   y_seq = y_seq.to(device=device)\n",
    "   query_y = query_y.to(device=device)\n",
    "\n",
    "   query_prob = model(x_seq, y_seq)[:, -1, :] # [batch_size, num_ways]\n",
    "   loss = criterion(query_prob, query_y)\n",
    "\n",
    "\n",
    "   with torch.no_grad():\n",
    "      _, query_preds = query_prob.max(dim=1)\n",
    "      accuracy = torch.eq(query_preds, query_y).float().mean()\n",
    "\n",
    "   return accuracy.item(), loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_folder: str, model: SNAIL, title: str) -> None:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "    filename = os.path.join(output_folder, title)\n",
    "\n",
    "    with open(filename, \"wb\") as f:\n",
    "        state_dict = model.state_dict()\n",
    "        torch.save(state_dict, f)\n",
    "    print(\"Model is saved in\", filename)\n",
    "\n",
    "\n",
    "def load_model(output_folder: str, model: SNAIL, title: str) -> None:\n",
    "    filename = os.path.join(output_folder, title)\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    print(\"Model is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph(\n",
    "    train_accuracies: List[float],\n",
    "    val_accuracies: List[float],\n",
    "    train_losses: List[float],\n",
    "    val_losses: List[float],\n",
    ") -> None:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    axs[0].plot(train_accuracies, label=\"train_acc\")\n",
    "    axs[0].plot(val_accuracies, label=\"test_acc\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(train_losses, label=\"train_loss\")\n",
    "    axs[1].plot(val_losses, label=\"test_loss\")\n",
    "    axs[1].set_title(\"Loss\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    config: Dict[str, Any]\n",
    ") -> Tuple[BatchMetaDataLoader, BatchMetaDataLoader, BatchMetaDataLoader]:\n",
    "    train_dataset = omniglot(\n",
    "        folder=config[\"folder_name\"],\n",
    "        shots=config[\"num_shots\"],\n",
    "        # test_shots=1, # default = shots\n",
    "        ways=config[\"num_ways\"],\n",
    "        shuffle=True,\n",
    "        meta_train=True,\n",
    "        download=config[\"download\"],\n",
    "    )\n",
    "    train_dataloader = BatchMetaDataLoader(\n",
    "        train_dataset, batch_size=config[\"task_batch_size\"], shuffle=True, num_workers=0\n",
    "    )\n",
    "\n",
    "    val_dataset = omniglot(\n",
    "        folder=config[\"folder_name\"],\n",
    "        shots=config[\"num_shots\"],\n",
    "        # test_shots=1, # default = shots\n",
    "        ways=config[\"num_ways\"],\n",
    "        shuffle=True,\n",
    "        meta_val=True,\n",
    "        download=config[\"download\"],\n",
    "    )\n",
    "    val_dataloader = BatchMetaDataLoader(\n",
    "        val_dataset, batch_size=config[\"task_batch_size\"], shuffle=True, num_workers=0\n",
    "    )\n",
    "\n",
    "    test_dataset = omniglot(\n",
    "        folder=config[\"folder_name\"],\n",
    "        shots=config[\"num_shots\"],\n",
    "        # test_shots=1, # default = shots\n",
    "        ways=config[\"num_ways\"],\n",
    "        shuffle=True,\n",
    "        meta_test=True,\n",
    "        download=config[\"download\"],\n",
    "    )\n",
    "    test_dataloader = BatchMetaDataLoader(\n",
    "        test_dataset, batch_size=config[\"task_batch_size\"], shuffle=True, num_workers=0\n",
    "    )\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"folder_name\": \"../load_dataset/dataset\",\n",
    "    \"download\": False,\n",
    "    \"num_shots\": 1,\n",
    "    \"num_ways\": 5,\n",
    "    \"output_folder\": \"saved_model\",\n",
    "    \"task_batch_size\": 32,  # 필수\n",
    "    \"num_task_batch_train\": 600,  # 필수\n",
    "    \"num_task_batch_test\": 200,  # 필수\n",
    "    \"device\": \"cuda\",  # 필수\n",
    "}\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloader(config)\n",
    "\n",
    "model = SNAIL(num_ways=config[\"num_ways\"], num_shots=config[\"num_shots\"]).to(\n",
    "    device=config[\"device\"]\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:58<00:00,  2.01it/s, train_accuracy=1.0000, train_loss=0.0274, val_accuracy=1.0000, val_loss=0.0298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved in saved_model\\snail.th\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 메타-트레이닝\n",
    "with tqdm(\n",
    "    zip(train_dataloader, val_dataloader), total=config[\"num_task_batch_train\"]\n",
    ") as pbar:\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for task_batch_idx, (train_batch, val_batch) in enumerate(pbar):\n",
    "        if task_batch_idx >= config[\"num_task_batch_train\"]:\n",
    "            break\n",
    "\n",
    "        train_accuracy, train_loss = train_snail(\n",
    "            num_ways=config[\"num_ways\"],\n",
    "            num_shots=config[\"num_shots\"],\n",
    "            device=config[\"device\"],\n",
    "            task_batch=train_batch,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "        val_accuracy, val_loss = test_snail(\n",
    "            num_ways=config[\"num_ways\"],\n",
    "            num_shots=config[\"num_shots\"],\n",
    "            device=config[\"device\"],\n",
    "            task_batch=val_batch,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "        )\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            train_accuracy=\"{0:.4f}\".format(train_accuracy),\n",
    "            val_accuracy=\"{0:.4f}\".format(val_accuracy),\n",
    "            train_loss=\"{0:.4f}\".format(train_loss),\n",
    "            val_loss=\"{0:.4f}\".format(val_loss),\n",
    "        )\n",
    "\n",
    "    # 모델 저장하기\n",
    "    save_model(output_folder=config[\"output_folder\"], model=model, title=\"snail.th\")\n",
    "\n",
    "    print_graph(\n",
    "        train_accuracies=train_accuracies,\n",
    "        val_accuracies=val_accuracies,\n",
    "        train_losses=train_losses,\n",
    "        val_losses=val_losses,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "load_model(output_folder=config[\"output_folder\"], model=model, title=\"snail.th\")\n",
    "\n",
    "# 메타-테스팅\n",
    "with tqdm(test_dataloader, total=config[\"num_task_batch_test\"]) as pbar:\n",
    "    sum_test_accuracies = 0.0\n",
    "    sum_test_losses = 0.0\n",
    "\n",
    "    for task_batch_idx, test_batch in enumerate(pbar):\n",
    "        if task_batch_idx >= config[\"num_task_batch_test\"]:\n",
    "            break\n",
    "\n",
    "        test_accuracy, test_loss = test_snail(\n",
    "            num_ways=config[\"num_ways\"],\n",
    "            num_shots=config[\"num_shots\"],\n",
    "            device=config[\"device\"],\n",
    "            task_batch=test_batch,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "        )\n",
    "\n",
    "        sum_test_accuracies += test_accuracy\n",
    "        sum_test_losses += test_loss\n",
    "        pbar.set_postfix(\n",
    "            test_accuracy=\"{0:.4f}\".format(sum_test_accuracies / (task_batch_idx + 1)),\n",
    "            test_loss=\"{0:.4f}\".format(sum_test_losses / (task_batch_idx + 1)),\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "543a2858b738eacd0ac3a1925ec6f5fb4c9073862b17acbfaa542a46096ac3bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
